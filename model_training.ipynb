{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVy-Jsg18TMg"
      },
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMuIcmbvMw3P"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/cleaned_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAaY5vPVNEmg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_dir)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5PH7BGAQODA"
      },
      "outputs": [],
      "source": [
        "category_counts = df['category'].value_counts()\n",
        "print(category_counts.index[3:])\n",
        "print(category_counts.values[3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFAVYZHtZ380"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "def synonym_replacement(words, n):\n",
        "    new_words = words.copy()\n",
        "    candidates = [w for w in words if wordnet.synsets(w)]\n",
        "    random.shuffle(candidates)\n",
        "    replaced = 0\n",
        "\n",
        "    for w in candidates:\n",
        "        syns = wordnet.synsets(w)\n",
        "        if syns:\n",
        "            synonym = syns[0].lemmas()[0].name()\n",
        "            new_words = [synonym if word == w else word for word in new_words]\n",
        "            replaced += 1\n",
        "        if replaced >= n:\n",
        "            break\n",
        "    return new_words\n",
        "\n",
        "\n",
        "def augment_sentence(sentence, num_aug):\n",
        "    words = sentence.split()\n",
        "    augmented = []\n",
        "    for _ in range(num_aug):\n",
        "        new_words = synonym_replacement(words, 1)\n",
        "        augmented.append(\" \".join(new_words))\n",
        "    return augmented\n",
        "\n",
        "\n",
        "def auto_balance(df, text_col, label_col):\n",
        "    # count rows each class\n",
        "    counts = df[label_col].value_counts()\n",
        "    max_count = counts.max()\n",
        "\n",
        "    new_rows = []\n",
        "\n",
        "    for label, count in counts.items():\n",
        "        need = max_count - count\n",
        "        if need == 0:\n",
        "            continue\n",
        "\n",
        "        df_class = df[df[label_col] == label]\n",
        "\n",
        "        while need > 0:\n",
        "            for sentence in df_class[text_col]:\n",
        "                if need <= 0:\n",
        "                    break\n",
        "                aug_sent = augment_sentence(sentence, 1)[0]\n",
        "                new_rows.append({text_col: aug_sent, label_col: label})\n",
        "                need -= 1\n",
        "\n",
        "    augmented_df = pd.DataFrame(new_rows)\n",
        "    final_df = pd.concat([df, augmented_df], ignore_index=True)\n",
        "    return final_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p8oqtqEZ7py"
      },
      "outputs": [],
      "source": [
        "df_balanced = auto_balance(df, text_col='clean_text', label_col='category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkbCJtkhblEx"
      },
      "outputs": [],
      "source": [
        "df_balanced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0QXjD_tZ-7h"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "category_counts = df['category'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=category_counts.index, y=category_counts.values, palette='viridis')\n",
        "plt.title('Số lượng mẫu trong từng chủ đề')\n",
        "plt.xlabel('Chủ đề')\n",
        "plt.ylabel ('Số lượng')\n",
        "plt.xticks(rotation=90)\n",
        "plt.savefig(\"barchart.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vTxrEz8b5jh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "category_counts = df_balanced['category'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=category_counts.index, y=category_counts.values, palette='viridis')\n",
        "plt.title('Số lượng mẫu trong từng chủ đề')\n",
        "plt.xlabel('Chủ đề')\n",
        "plt.ylabel ('Số lượng')\n",
        "plt.xticks(rotation=90)\n",
        "plt.savefig(\"barchart2.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTmCOMxT8yNr"
      },
      "source": [
        "# BoW + MNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_e07dnZ6A6d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "X = df_balanced['clean_text']\n",
        "y = df_balanced['category']\n",
        "\n",
        "#chia dữ liệu\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "# Fit vectorizer trên train\n",
        "vectorizer = CountVectorizer(max_features=30000, ngram_range=(1,2), min_df=2, stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec  = vectorizer.transform(X_test)\n",
        "\n",
        "# Train\n",
        "clf_mnb = MultinomialNB(alpha=1.0)\n",
        "clf_mnb.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf_mnb.predict(X_test_vec)\n",
        "print(\"Acc:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Lưu model + vectorizer\n",
        "joblib.dump(vectorizer, \"countvec.joblib\")\n",
        "joblib.dump(clf_mnb, \"mnb_model.joblib\")\n",
        "\n",
        "# Dùng cho 1 đoạn văn mới\n",
        "vec = joblib.load(\"countvec.joblib\")\n",
        "model = joblib.load(\"mnb_model.joblib\")\n",
        "new_text = \"Tesla shares surged more than 12% in pre-market trading on Monday after the electric vehicle maker reported record quarterly deliveries that far exceeded Wall Street expectations, despite ongoing supply chain challenges and factory shutdowns in China.\"\n",
        "new_vec = vec.transform([new_text])\n",
        "pred = model.predict(new_vec)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4s9gElQNxdT"
      },
      "source": [
        "# dùng TF_IDF + LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R50B5m4pN2TH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "df_balanced = df_balanced.dropna(subset=['clean_text', 'category']).reset_index(drop=True)\n",
        "\n",
        "X = df_balanced['clean_text']\n",
        "y = df_balanced['category']\n",
        "\n",
        "#chia dữ liệu\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=30000, ngram_range=(1,2), min_df=2,stop_words='english',)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec  = vectorizer.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(\n",
        "    C=5.0,\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    n_jobs=-1,\n",
        "    solver='saga',\n",
        "    penalty='l2',\n",
        "    tol=1e-4,\n",
        ")\n",
        "\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "print(f\"Acc: {accuracy_score(y_test, y_pred)}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Lưu model + vectorizer\n",
        "joblib.dump(vectorizer, \"tfidf_v6.joblib\")\n",
        "joblib.dump(clf, \"nb_model_v6.joblib\")\n",
        "\n",
        "# Dùng cho 1 đoạn văn mới\n",
        "vec = joblib.load(\"tfidf_v6.joblib\")\n",
        "model = joblib.load(\"nb_model_v6.joblib\")\n",
        "new_text = \"Tesla shares surged more than 12% in pre-market trading on Monday after the electric vehicle maker reported record quarterly deliveries that far exceeded Wall Street expectations, despite ongoing supply chain challenges and factory shutdowns in China.\"\n",
        "new_vec = vec.transform([new_text])\n",
        "pred = model.predict(new_vec)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2MhxZ20khC4"
      },
      "source": [
        "# biểu đồ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_S41lwWjEBc"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=df_balanced['category'].unique(), yticklabels=df_balanced['category'].unique(), cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.savefig(\"confmat.png\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}